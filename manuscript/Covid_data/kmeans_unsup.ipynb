{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import MeanShift\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "### \n",
    "### This includes code copied and pasted from the main methods used for the website in BioKlustering-Website/BioKlustering/mlmodel/parser/kmeans.py\n",
    "### These methods are copy-pasted instead of directly included due to difficulties importing Django classes for running locally without running the server\n",
    "###\n",
    "\n",
    "def parseFasta(data):\n",
    "    d = {fasta.id : str(fasta.seq) for fasta in SeqIO.parse(data, \"fasta\")}\n",
    "    pd.DataFrame([d])\n",
    "\n",
    "    s = pd.Series(d, name='Sequence')\n",
    "    s.index.name = 'ID'\n",
    "    s.reset_index()\n",
    "    return pd.DataFrame(s)\n",
    "\n",
    "def kmerXTable(s, a, b):\n",
    "    tfid_vector = TfidfVectorizer(analyzer='char', ngram_range=(a,b))\n",
    "    s_hat = tfid_vector.fit_transform(s.Sequence)\n",
    "    kmerNames = tfid_vector.get_feature_names()\n",
    "    kmers = s_hat.toarray()\n",
    "    return pd.DataFrame(kmers,columns=kmerNames, index = s.index)\n",
    "    \n",
    "def kmeans(fasta, cNum, klength_min = 6, klength_max = 6, rNum = 50):\n",
    "    inputData = parseFasta(fasta)\n",
    "#     temp = virus01.append(inputData)\n",
    "#     temp = temp.drop_duplicates(keep=\"last\")\n",
    "        \n",
    "    inputData[\"Sequence\"] = inputData[\"Sequence\"].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "    kmerXTableInput = kmerXTable(inputData, klength_min, klength_max)\n",
    "        \n",
    "        \n",
    "    #km = KMeans(random_state = rNum, n_clusters = cNum)\n",
    "    #m.fit(kmerXTableInput) \n",
    "    #y_hat = km.predict(kmerXTableInput)\n",
    "    PCAembedding = PCA(n_components=10)\n",
    "    NkmerXTableInput = preprocessing.normalize(kmerXTableInput)\n",
    "    PCAembedding_low = PCAembedding.fit_transform(NkmerXTableInput)\n",
    "    \n",
    "    ms = MeanShift()\n",
    "    ms.fit(PCAembedding_low)\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    n_cluster_centers = len(cluster_centers)\n",
    "\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        kmms = KMeans(init = cluster_centers, n_clusters = n_cluster_centers)\n",
    "        #kmms = KMeans(init = 'k-means++', n_clusters = 2, n_init=20, max_iter=600)\n",
    "        y_hat = kmms.fit_predict(PCAembedding_low)\n",
    "\n",
    "    if n_cluster_centers > cNum:\n",
    "        res = y_hat\n",
    "        unique_predicted_labels = get_unique_numbers(res)\n",
    "        predicted_labels_count = {}\n",
    "        for label in unique_predicted_labels:\n",
    "            predicted_labels_count[label] = (res == label).sum()\n",
    "        max_item = max(predicted_labels_count, key=predicted_labels_count.get)\n",
    "        predicted_labels_count = sorted(predicted_labels_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        map_predict_to_actual = {}\n",
    "        max_value = cNum-1\n",
    "        for i in range(len(predicted_labels_count)):\n",
    "            if i < max_value:\n",
    "                map_predict_to_actual[predicted_labels_count[i][0]] = i\n",
    "            else:\n",
    "                # print(f\"{predicted_labels_count[i][0]} mapped to {max_value}\")\n",
    "                map_predict_to_actual[predicted_labels_count[i][0]] = max_value\n",
    "\n",
    "        # predictions_final contains the final results\n",
    "        # it takes care of the case when num_class > number of unique labels given\n",
    "        predictions_final = []\n",
    "        print(f\"res: {res}\")\n",
    "        print(f\"map_predict_to_actual: {map_predict_to_actual}\")\n",
    "        for i in range(len(res)):\n",
    "            if res[i] in map_predict_to_actual.keys():\n",
    "                predictions_final.append(map_predict_to_actual[res[i]])\n",
    "            else:\n",
    "                predictions_final.append(map_predict_to_actual[max_item])\n",
    "        # print(predictions_final)\n",
    "        y_hat = np.array(predictions_final)\n",
    "\n",
    "        \n",
    "    return y_hat, kmerXTableInput\n",
    "\n",
    "def get_unique_numbers(numbers):\n",
    "\n",
    "    list_of_unique_numbers = []\n",
    "\n",
    "    unique_numbers = set(numbers)\n",
    "\n",
    "    for number in unique_numbers:\n",
    "        list_of_unique_numbers.append(number)\n",
    "\n",
    "    return list_of_unique_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MT994979.1</th>\n",
       "      <td>AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MZ043011.1</th>\n",
       "      <td>ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT994951.1</th>\n",
       "      <td>AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MT994950.1</th>\n",
       "      <td>AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MW010029.1</th>\n",
       "      <td>AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Sequence\n",
       "ID                                                           \n",
       "MT994979.1  AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...\n",
       "MZ043011.1  ATTAAAGGTTTATACCTTCCCAGGTAACAAACCAACCAACTTTCGA...\n",
       "MT994951.1  AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...\n",
       "MT994950.1  AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC...\n",
       "MW010029.1  AACCAACCAACTTTCGATCTCTTGTAGATCTGTTCTCTAAACGAAC..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./size_500_test.fasta\"\n",
    "ouput_df = parseFasta(path)\n",
    "ouput_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res: [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  3  0  0  0  0\n",
      "  0  0  0  0  0  2  0  0  0  0  1  0  0  0  2  0  1  2  1  0  0  0  0  0\n",
      "  0  0  0  2  0  2  0  1  0  0  0  0  0  0  0  0  0  1  0  0  2  0  1  1\n",
      "  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0\n",
      "  2  2  0  1  0  0  0  0  1  2  7  2  1  1  1  1  1  1  1  1  1  3  1  0\n",
      "  0  2  1  1  2  2  1  1  3  1  1  4  1  1  1  3  7  1  1  2  4  1  1  1\n",
      "  0  1  1  1  2  1  8  1  1  1  1  1  1  1  1  1  4  4  1  1  1  1  1  2\n",
      "  5  1  3  5  1  2  0  1  1  1  1  2  9  1  2  2 10  1  1  1  2  1  1  1\n",
      "  1  1  1  1  1  1  1  6  1  1  6  1  0  0  0  0  0  0  0  2  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  4  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "map_predict_to_actual: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4, 6: 4, 7: 4, 8: 4, 9: 4, 10: 4}\n"
     ]
    }
   ],
   "source": [
    "from operator import mod\n",
    "\n",
    "\n",
    "fasta = \"./size_500_test.fasta\"\n",
    "klength_min = 3\n",
    "klength_max = 3\n",
    "cNum = 5\n",
    "seed = 1232\n",
    "predictions1, x = kmeans(fasta, cNum, klength_min, klength_max, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.242"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "actual_label = pd.read_csv(\"./size_500_test.csv\")\n",
    "sum(actual_label['class'] == predictions1)/len(predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = list(range(1, len(predictions1)+1))\n",
    "df = pd.DataFrame(list(zip(number, predictions1)), \n",
    "               columns =['Number', 'Labels']) \n",
    "df.to_csv('kmeans_unsup_predictions.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents,columns = ['principal component 1', 'principal component 2'])\n",
    "finalDf = pd.concat([principalDf, pd.Series(predictions1)], axis = 1)\n",
    "finalDf = pd.concat([finalDf, pd.Series(actual_label['class'])], axis = 1)\n",
    "finalDf.columns = ['principal Component 1', 'Principal Component 2','Predicted Label', 'Actual Label']\n",
    "finalDf.to_csv('kmeans_unsup_pca.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
